## 技术关键点思考与经验认识

### 1)JVM

JVM里的关键点，主体是**GC的选择与参数设置**，这些要求开发人员掌握JVM内存模型，GC类型，设置的参数，GC日志的解读，以及工具与命令的使用。

学习JVM主体是为了解决针对特定（生产）环境，选择合适的GC，并设置合适堆栈内存以及GC其他参数，并在程序过程中避免内存泄漏和内存溢出的问题，最终减少整个程序的GC次数。一次都不GC是不可能的，但是通过选择不同的GC和参数设置，可以GC频率和暂停时长，这对程序时非常重要的。

经验之谈：

- JVM堆内存设置到机器总内存的70%~75%，因为还有非堆与堆外内存的存在；
- 发生频繁GC有可能是过早提升引起，可以根据课上讲的症状进行判断，解决起来是让年轻代能放下临时数据即可。

### 2)NIO

NIO里的关键点，主体是**netty**，这要求开发人员理解原始socket通信是什么样子，之后IO模型演进的过程中，如何提升了IO效率。这里netty基于NIO，事件驱动的异步网络应用开发框架。

netty中将socket连接和数据处理分开，由boss group负责接收外部连接，然后分发给worker group，worker group会给到某个具体的EventLoop处理，它将任务交给当前Channel去做，Channel就按PipleLine中的ChannelHandler一个一个处理。

经验之谈：

- 当使用到netty实现网络应用开发，一定不要阻塞EventLoop。
- 另外缓存区，心跳机制也需要根据实际发包频率，进行调节，网络传输最大传输单元是1500Byte，其中数据最大占1460，如果单次发送数据量少，且发送频率高，这不仅浪费网络传输资源，还容易造成网络阻塞。

### 3) 并发编程

并发编程里的关键点，主体是**JUC包和线程池的使用**，这些要求开发人员知道线程创建的方式，常用方法以及线程的状态，使用线程池更好的管理多线程，另外为了解决多线程执行时产生的并发问题（原子性，可见性以及有序性），JUC提供了synchronized，volatile，锁以及工具类。

JUC中提供了Lock，Condition，ReadWriteLock等锁机制类，AtomicXxx的原子操作类，CountDownLatch, CyclicBarrier, Semaphore  信号量类以及并发的集合类。

经验之谈：

- 锁的粒度，锁与性能平衡，锁的可重入性，是否需要公平，乐观锁的自旋
- 线程共享与协作，Lock与synchronized，Future/Callable，Thread#join()，CountdownLatch以及CyclicBarrier

### 4)Spring 和 ORM 等框架

Spring和ORM框架里的关键点，主体是**Spring，Spring Boot以及MyBatis**，另外介绍了java8特性，Guava工具包，并扩展了设计原则和设计模式，再捎带了单元测试。

Spring改变了传统web项目的结构，分出了Controller，Service，DAO，Model层，并通过IOC，Spring Bean让对象的创建销毁可以完全托管给Spring容器，Bean的配置和使用通常有XML和注解两种，而注解在Spring Boot开始之后，成为了主流的一种方式。Spring Boot的核心思想是约定大于配置，让一切变得简化，这得利于自动化配置；另一方面，由于成熟的第三方组件集成经验，各种spring-boot-starter，这构建了一套快速配置的脚手架，开发起来如此丝滑。

ORM框架最常见的是Hibernate和MyBatis，Hibernate旨在让开发人员从SQL语句中解放开来，由框架内构建SQL，俗称全自动化；而MyBatis则将SQL的编写交由开发人员，俗称半自动化，当然它有其他配合的工具，能够自动生成操作数据的XML配置。

经验之谈：

- 本地事务，如果事务超出了Spring事务的管理范围，则Spring事务的设置无法生效
- 多数据源，使用时一定要指定使用的是哪个数据源
- 连接池的配置，池的大小不能太大，几十以内可以，尽可能的设置心跳和重连，避免应用需要人工重启，还有就是超时时间
- ORM内尽量避免复杂SQL，级联查询，一方面有可能锁表，另一方有可能捞出来太多不需要数据
- ORM辅助工具与插件，这部分按照业务简单还是复杂取舍，如果业务复杂，尽量少用这类插件工具

### 5)MySQL 数据库和 SQL

Mysql数据库和SQL里的关键点，主体是**SQL优化，事务与锁**，这里由浅入深，介绍数据库原理，表设计原则，事务和锁，进入具体到SQL优化，配合优化，最后扩展到数据库的集群相关问题。

SQL语言是结构化查询语言，包含六类，但常用的是查询，操作和定义语言；MySQL数据库可以使用SQL语言进行操作，它的表设计有设计范式，用来约束表的设计合理性，但不是必须如此。MySQL一个简化的执行流程，包含查询缓存（8.0之后没有了），解析器解析语句，然后预处理，再是查询优化器进行优化，执行计划，最后查询执行引擎并调用api进行数据操作。这里需要着重学习MySQL索引，它是使用B+树来检索，如果想索引检索够快，那么尽量减少树高。

MySQL事务可靠性模型，具有原子性，一致性，隔离性以及持久性，由事务扩展出四种隔离级别，它保证可靠性的机制，undo log以及redo log。在对数据进行操作，与多线程相同，也有锁的概念，这里有表级锁和行级锁。

经验之谈：

- 参数配置优化，可以调节连接请求，缓冲区，（常用）Innodb引擎参数设置
- 数据库表设计，数据类型尽量明确和小，少用外键和触发器，适当可以增加冗余字段，避免物理删除记录，时间戳的字段大多数情况可以考虑加上
- 写入优化，多使用PreparedStatement减少SQL解析 ，多使用批操作，减少交互
- 数据更新，避免gap lock，避免锁范围扩大，减少范围更新
- 查询优化，使用like时字符串开头不能模糊查询，尽量利用前缀匹配，全文检索尽量使用专职解决方案，比如ES；连接查询，避免笛卡尔积查询
- 索引失效，像条件中NULL，not，not in，以及使用函数，另外减少使用or
- 查询数量与次数，根据业务平衡这两者，避免使用临时文件排序或临时表，避免不必须的重复数据传输

### 6)分库分表

Mysql数据库和SQL里的关键点，主体是**MySQL主从，读写以及高可用，垂直和水平拆分，XA、BASE分布式事务，TCC/AT相关框架**，中间穿插了一些背景知识，以及数据迁移。

MySQL主从复制核心是主库写bin log，从库拉取bin log产生relay log，并执行里面的内容，实现主从复制，后来引入基于Paxos协议实现的组复制，保障数据一致性。在有了主从之后，可以让业务进行读写分离，降低单节点的压力，通过业务侧加上心跳，断线重连，故障转移，灾难恢复，让业务不间断完善高可用，MySQL高可用使用MGR和MySQL Innodb Cluster技术。

主从结构解决了高可用，读扩展，但写的能力没有变化，分库分表能解决这个问题。按照业务拆分，属于垂直分库分表，向（微）服务化方向演进，按照数据拆分，属于水平分库分表，这种可以任意拆分扩展。另外还需要注意数据迁移方式，binlog+全量+增量完成数据迁移。

数据库拆分后，就有了分布式事务的需求，XA属于强一致性分布式事务，数据库支持，由一个全局的事务管理器对多个资源管理器进行事务管理，应用程序在事务边界内对资源进行操作，由于中间多个了prepare状态，属于两阶段事务。BASE属于柔性事务，强调最终一致性，中间状态可以不一致，BASE事务常见模式有TCC和AT。TCC模式第一阶段进行try来检查并预留相关资源，第二阶段根据业务try状态来操作，成功则confirm，失败则cancel；AT模式第一阶段也是执行SQL，但解析SQL同时会保留执行前的状态，第二阶段成功后不会有其他处理，如果失败则根据前面解析的SQL和执行前的状态，生成反向SQL。

经验之谈：

- 多个数据库实例不放在一个主机/机架
- 多地多中心容灾高可用
- 垂直拆分做法，1）梳理拆分范围与影响范围，2）评估和重构影响到的服务，3）准备新数据库集群复制数据，4）修改系统配置并发布上线
- 垂直拆分，先拆分系统还是拆分数据库，拆分范围都需要动工之前调研清楚
- 水平拆分做法，按照数据特点，将数据库的数据进行拆分，分散到多个数据库和表中
- 尽量使用简单SQL
- 使用XA分布式事务，一般情况不需要调整隔离级别
- XA虽然保证一致性，但不能100%，所以一定要安排监控和适当的人工处理
- TCC模式需要允许空回滚，防悬挂以及业务幂等设计
- XA适合简单分布式事务，BASE适合复杂分布式事务

### 7)RPC 和微服务

RPC和微服务里的关键点，主体是**RPC原理，dubbo最佳实践，服务注册与发现，微服务最佳实践**，这中间介绍了RPC背景知识，dubbo的技术原理，源码阅读，分布式服务的集群，路由，流控，以及微服务架构下的介绍。

RPC原理是通过本地有个代理存根，本地调用远程服务时，通过这个存根对调用信息进行序列化，传输给远程服务端，服务端反序列化之后给到服务存根，服务存根找到真实服务并将请求给带该服务进行处理，最后将结果返回给本地存根，存根再给到本地业务。

Dubbo基本流程是provider注册到Registry，consumer到Registry订阅，Registry通知consumer拿到provider信息，进行invoke。

当有很多服务时，就需要服务的注册与发现机制，这里会有注册中心，配置中心以及元数据中心，注册中心为了解决服务注册与发现，配置中心为了解决系统不同的配置。元数据则是管理各个节点之间的元数据信息。服务路由为了服务负载均衡，服务过滤则为复杂处理提供增强，服务流控有限流，降级以及过载保护。

服务提高内聚后，数量增多变得复杂后，渐渐发展出微服务架构，它适合大规模且复杂度高的系统使用。

经验之谈：

- dubbo开发分包建议将服务接口、 服务模型、 服务异常等均放在 API 包中
- 服务接口尽可能大粒度， 每个服务方法应代表一个功能 ，而不是某功能的一个步骤 
- 服务接口建议以业务场景为单位划分  
- 不建议使用过于抽象的通用接口
- 规模大了，需要环境隔离与分组，好的话部署多套，资源紧张可以使用多注册中心，group机制，version
- dubbo的provider配置consumer的属性timeout，retries，loadbalance
- dubbo的provider配置provider的属性threads，executes
- 容器化时，容器服务的网络复用宿主机，或者指定注册的ip
- dubbo的重试与幂等设计，dubbo默认重试2次
- 实现自己的xx中心，最需要的是有存取数据能力以及数据变化时实时通知机制
- 针对遗留系统改造，需要功能剥离，数据解耦，逐步拆分，快速迭代，灰度发布，谨慎试错，提高质量线
- 分阶段拆分准则不同，每个阶段都需要高内聚低耦合
- 拆分可以使用扩展立方体
- 加强建设自动化测试，部署以及运维监控
- 事务上注意幂等，去重，补偿，慎用分布式事务

### 8) 分布式缓存

分布式缓存里的关键点，主体是**缓存常见问题，Redis，集群下缓存高可用**，此外，还介绍了缓存的特点，类型以及策略。

缓存的存在，是为了平衡系统各级处理速度，提升系统性能。缓存使用不当，会导致系统需要预热，启动慢，再就是容易内存资源耗尽。缓存一开始多见于本地缓存，简单易实现，但容易占用资源，影响业务执行，由此出现远程缓存，类似redis。

Redis（REmote DIctionary Server）是一个key-value存储系统，使用ANSI C语言编写、 遵守BSD协议、 支持网络、 可基于内存亦可持久化的日志型、 Key-Value数据库， 并提供多种语言的API。常用的数据结构，字符串，散列，列表，集合以及有序集合，高级数据结构Bitmaps，Hyperloglogs以及GEO。Redis的IO线程在6之后是多线程，内存处理线程一直是单线程。常见的使用场景，数据缓存，业务去重和排序，全局一致计数，发布订阅以及分布式锁。

Redis有着主从复制，同时带有Sentinel进行监控，当主发生切换时，选出新主；同样的，Redis从容量角度，走向分片，Redis Cluster通过一致性hash的方式，将数据分散到多个服务器节点。这里Redis有个分布式组件库，Redission，此外还有个强大的内存网格技术Hazelcast。

缓存使用时常见的问题，缓存穿透，大量并发查询不存在的KEY，导致都直接将压力透传到数据库；缓存击穿，某个KEY失效的时候，正好有大量并发请求访问这个KEY；缓存雪崩，当某一时刻发生大规模的缓存失效的情况，会有大量的请求进来直接打到数据库，导致数
据库压力过大升值宕机。  

经验之谈：

- 使用频率高的热数据适合缓存
- 读写比大的适合缓存
- 变动频率高的，一致性要求强的数据不适合缓存
- 注意监控系统缓存有效性，1）读写比N:1，2）命中率达90%
- 缓存设计与使用需要考虑容量和过期策略
- 缓存穿透的解决办法，1）缓存不存在的key，2）完全以缓存为准，3）Bloom过滤或RoaringBitmap判断KEY是否存在  
- 缓存击穿的解决办法，1）key的更新操作添加全局互斥锁，2）完全以缓存为准
- 缓存雪崩的解决办法，1）更新策略在时间上均匀，2）热数据尽量分散到不同机器，3）做主从或者多副本，4）熔断限流机制
- 尽量每个业务集群单独使用自己的redis
- 控制Redis资源的申请与使用，规范环境和Key的管理  
- 当监控CPU 100%，需要优化高延迟的操作  

### 9) 分布式消息队列

分布式消息队列里的关键点，主体是**消息模式与消息协议，常见消息中间件的使用**，这里介绍了队列与消息异同，消息中间件有ActiveMQ，Kafka，RabbitMQ，RocketMQ，Pulsar以及不同系统间的数据交互Camel，Spring Integration。

分布式系统里，实现异步通信，简化依赖，能够缓冲，又有一定可靠性，在这些需求下，出现了产生了消息队列，消息队列类似队列结构，存储的数据有序，常见作用为异步通信，系统解耦，削峰平谷以及可靠性通信。它常见的消息处理模式有点对点，对应Queue，消息只能被一个消费者消费；另一种是发布订阅模式，对应Topic，消息能被多个订阅者消费。

消息处理的保障，三种Qos，1）At most once，至多一次，消息可能丢失但是不会重复发送；2）At least once，至少一次，消息不会丢失，但是可能会重复；3）Exactly once，精确一次， 每条消息肯定会被传输一次且仅一次。消息的事务性依靠确认机制或者事务管理器。

消息协议有STOMP，JMS，AMQP，MQTT，XMPP以及Open Messaging，JMS协议关注于应用层的API协议（客户端协议），类似JDBC，局限在了java。

消息中间件分为三代，一代是ActiveMQ/RabbitMQ，基于JMS和AMQP，不支持内存堆积，二代是Kafka/RocketMQ，核心还是Kafka，支持磁盘与消息堆积，三代是Pulsar，在二代上面将计算与存储分离。这里主体介绍目前使用最广的Kafka，它的时间复杂度为O(1)，高吞吐率，支持Kafka Server的消息分区，支持实时和离线两种处理，支持在线水平扩展。

Kafka中Producer发布消息到Broker，Broker有多个Topic，Consumer Group里有多个Consumer，每个Consumer消费Topic部分信息，一个Group所有Consumer合起来是一个完整Topic，每个Topic包含一个或多个Partition。

经验之谈：
